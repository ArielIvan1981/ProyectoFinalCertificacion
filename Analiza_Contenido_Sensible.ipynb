{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielIvan1981/ProyectoFinalCertificacion/blob/main/Analiza_Contenido_Sensible.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ66MxGVRMHS"
      },
      "source": [
        "Instalo las librerias a utilizar, usaremos BeautifulSoup, Requests y el Parser (el parser sirve para extraer la informacion de html) usaremos lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pMaUlBRpbZIj"
      },
      "outputs": [],
      "source": [
        "#pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ORzPk2KYbibm"
      },
      "outputs": [],
      "source": [
        "#pip install lxml #usamos el parser lxml para obtener data del codigo html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XDiKbIdsbPku"
      },
      "outputs": [],
      "source": [
        "#pip install bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyZSGFwRmaF"
      },
      "source": [
        "Llamamos a las librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BpQF-cmuc5s3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a145006-a434-42a6-c2f1-ceb276f39642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import termcolor\n",
        "import os\n",
        "os.system('color')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7znxKgRr3s"
      },
      "source": [
        "Le pedimos al usuario que ingrese por teclado la url a analizar, esto se hara manualmente en un principio pero luego se buscara la manera que se haga de forma automatica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ggLa0vbuE4",
        "outputId": "e0875b47-4279-406f-84be-6f1d326091e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingrese enlace a analizar: https://www.infobae.com/sociedad/policiales/2022/07/29/misterio-por-el-crimen-de-un-gendarme-en-rosario-encontraron-su-cuerpo-en-el-fondo-de-un-aljibe-y-hay-sospechas-sobre-su-ex-pareja/\n"
          ]
        }
      ],
      "source": [
        "website=input(\"Ingrese enlace a analizar: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpUW6coqTe7v"
      },
      "source": [
        "Usamos requests para mandar una solicitud al servidor y obtener el codigo html de la pagina web y lo asignamos a la variable result, me muestra la respuesta de la pagina a la solicitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MVzzzbAnb5F0"
      },
      "outputs": [],
      "source": [
        "result=requests.get(website)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWnRthpmWa_P"
      },
      "source": [
        "A continuacion obtenemos el texto del resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_fGctSp5dgF9"
      },
      "outputs": [],
      "source": [
        "content=result.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-NfVPKlU96z"
      },
      "source": [
        "Creamos una variable soup, nos permitira localizar elementos en una pagina web. En soup ya tenemos la pagina en codigo html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oziP2yEPd13T"
      },
      "outputs": [],
      "source": [
        "soup=BeautifulSoup(content, 'lxml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_13e7lScPIX"
      },
      "source": [
        "Creamos la variable title para obtener el titular de la noticia. Para ello, buscamos el box html donde suele estar el titulo en los principales portales. Si no estamos trabajando con ninguno de ellos, usamos la etiqueta h1 del html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zU6_5Z-HjV59"
      },
      "outputs": [],
      "source": [
        "title=None\n",
        "def find_title(x):\n",
        "  '''Funcion para encontrar el titulo de\n",
        "  la noticia, dependiendo el diseno html del\n",
        "  portal. Argumento \"x\" es\n",
        "  un objeto soup'''\n",
        "  box=None\n",
        "  global title\n",
        "  if 'pagina12' in website:\n",
        "    box=x.find('article', class_= 'article-full section')\n",
        "  elif 'infobae' in website:\n",
        "    box=x.find('div', class_='article-header')\n",
        "  elif 'lanacion' in website:\n",
        "    box=x.find('div', class_='lay --apertura')\n",
        "  elif 'clarin' in website:\n",
        "    box=x.find('div',\n",
        "                  class_='entry-title col-lg-6 col-md-12 col-sm-12 col-xs-12')\n",
        "  elif 'lavoz' in website:\n",
        "    box=x.find('div', class_='px2 story-headline')\n",
        "  elif 'laizquierdadiario' in website:\n",
        "    box=x.find('div', class_='header-articulo')\n",
        "  else:\n",
        "    title=x.find('h1').get_text()\n",
        "\n",
        "  if box is not None:\n",
        "    title=box.find('h1').get_text()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fIOvhC7ukgqi"
      },
      "outputs": [],
      "source": [
        "find_title(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPPROf9Fchox"
      },
      "source": [
        "Realizamos lo mismo para el subtitulo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0CJv8HEJkw7L"
      },
      "outputs": [],
      "source": [
        "subtitle=None\n",
        "def find_subtitle(x):\n",
        "  '''Funcion para encontrar el subtitulo de\n",
        "  la noticia, dependiendo el diseno html del\n",
        "  portal. Argumento \"x\" es\n",
        "  un objeto soup'''  \n",
        "  global subtitle\n",
        "  if 'pagina12' in website:\n",
        "    subtitle=x.find('h3').get_text()\n",
        "  elif 'infobae' in website:\n",
        "    subtitle=x.find('h2').get_text()\n",
        "  elif 'lanacion' in website:\n",
        "    subtitle=x.find('h2').get_text()\n",
        "  elif 'laizquierdadiario' in website:\n",
        "    subtitle=x.find('p').get_text()\n",
        "  elif 'lavoz' in website:\n",
        "    subtitle=x.find('div', class_='story-subtitle').get_text()\n",
        "  elif 'clarin' in website:\n",
        "    subtitle=x.find('div', class_='bajada').get_text()\n",
        "  elif 'quorum.gt' in website:\n",
        "    subtitle=x.find('div', class_='post-excerpt').get_text()\n",
        "  else:\n",
        "    subtitule=x.find('h2').get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1CjqZB7SliOh"
      },
      "outputs": [],
      "source": [
        "find_subtitle(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MHlLL1bcsB_"
      },
      "source": [
        "Buscamos el contenido del texto. Al igual que con el titulo, buscamos en el box donde suele estar el parrafo en los principales portales, luego extraemos el texto con la etiqueta 'p' de html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jEY2WFIgrJy3"
      },
      "outputs": [],
      "source": [
        "parrafo=None\n",
        "def find_parrafo(x):\n",
        "  ''' Funcion para encontrar el contenido de la noticia\n",
        "  dependiendo el diseno html del portal. Argumento \"x\" es\n",
        "  un objeto soup'''\n",
        "  box=None\n",
        "  global parrafo\n",
        "  if 'pagina12' in website:\n",
        "    box=x.find('article', class_='article-main-content article-text')\n",
        "  elif 'infobae' in website:\n",
        "    box=x.find('div', class_='nd-body-article')\n",
        "  elif 'lanacion' in website:\n",
        "    box=x.find('div', class_='col-12')\n",
        "  elif 'laizquierdadiario' in website:\n",
        "    box=x.find('div', class_='col-md-10 offset-md-1')\n",
        "  elif 'lavoz' in website:\n",
        "    box=x.find('section')\n",
        "  elif 'clarin' in website:\n",
        "    box=x.find('div', class_='body-nota')\n",
        "  else:\n",
        "    parrafo=x.find('article').get_text()\n",
        "  \n",
        "  if box is not None:\n",
        "    parrafo=box.find('p').get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L4mRx1tBWPQE"
      },
      "outputs": [],
      "source": [
        "#Intentamos encontrar el parrafo con la funcion find_parrafo. \n",
        "#Si no lo encuentra, se imprime 'No se encontro parrafo', y esa variable continuara siendo None.\n",
        "try:\n",
        "  find_parrafo(soup)\n",
        "except:\n",
        "  print('No se encontro parrafo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYdiSMJFwEeY"
      },
      "source": [
        "Creamos la variable texto_a_analizar para ir concatenenado titulo, subtitulo y contenido de la noticia a analizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wNGtTV_w4mB5"
      },
      "outputs": [],
      "source": [
        "texto_a_analizar = f\"{title} \\n{subtitle} \\n{parrafo}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NJdpfK_ckbCW"
      },
      "outputs": [],
      "source": [
        "ls_words = texto_a_analizar.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHH2kwqKfMzr"
      },
      "source": [
        "Creamos una lista con las palabras clave que queremos buscar en el texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mO1_rF_VrhuV"
      },
      "outputs": [],
      "source": [
        "ls_triggerwords= ['sangre', 'mató', 'mataron', 'asesinato', \n",
        "                  'fallecido', 'muerto', 'asesinaron', 'asesinó', \n",
        "                  'cadaver', 'sicarios', 'asesino', 'tiro', \n",
        "                  'dispararon', 'ejecutaron', 'ejecución', 'muertos',\n",
        "                  'accidente', 'víctima', 'violación', \n",
        "                  'chocaron', 'exterminio', 'crimen', 'decapitaron']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEyudBSxwEed"
      },
      "source": [
        "Creamos la funcion para evaluar si en la noticia se encuentra alguna de la palabras o etiquetas que determinaran si el contenido de la noticia es sensible o no."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "b-1Y_gxVrpgJ"
      },
      "outputs": [],
      "source": [
        "def find_trigger_words(x):\n",
        "  global ls_triggerwords\n",
        "\n",
        "  bandera = 0\n",
        "  for w in x:\n",
        "    if w in ls_triggerwords:\n",
        "      bandera = 1\n",
        "      break\n",
        "    else:\n",
        "      bandera = 0\n",
        "\n",
        "  if bandera == 1:\n",
        "    print(termcolor.colored('Precaucion Noticia con contenido sensible', 'red'))\n",
        "  else:\n",
        "    print(termcolor.colored('Noticia sin contenido sensible', 'green'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VvQczxuokNq",
        "outputId": "bada78f1-0503-449e-faaa-8690b2c98460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mPrecaucion Noticia con contenido sensible\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "find_trigger_words(ls_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Analiza_Contenido_Sensible.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}